{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 42 pages from PDF.\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "from langchain.embeddings import fastembed  # Assuming fastembed is compatible here\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set up for ChromaDB\n",
    "client = Client(Settings())\n",
    "\n",
    "# First document\n",
    "pdf_path = \"../backend/data/ersattningsmodell_vaders_2019.pdf\"\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        raise ValueError(\"Input must be a string.\")\n",
    "\n",
    "    # Remove excessive newlines and leading/trailing whitespace\n",
    "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to parse PDF and convert to Documents\n",
    "def parse_pdf_with_pypdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF using PyPDF2 and converts each page to a LangChain Document.\"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    documents = []\n",
    "    \n",
    "    for page_num, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            cleaned_text = clean_text(text)  # Clean the text immediately after extraction\n",
    "            documents.append(Document(page_content=cleaned_text, metadata={\"page_number\": page_num + 1}))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Load PDF and parse it\n",
    "docs = parse_pdf_with_pypdf(pdf_path)\n",
    "\n",
    "# Cleaning the text of each document\n",
    "for doc in docs:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(f\"Extracted {len(docs)} pages from PDF.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018- 09-05 3 1 Allmänt 1.1 Beräkningsmodell En bra beräkningsmodell kräver, utifrån vinterns karaktär, två väl fungerande delmodeller för att reglera kostnader för vinterväghållningsåtgärder mellan beställare och utförare. − En delmodell som beskriver vädret under vintersäsongen − En delmodell som kopplar väderbeskrivningar till åtgärdsbehov/r esursinsatser, dock inte nödvändigtvis i ett 1 -1- förhållande. Denna rapport redovisar i detalj hur Trafikverket s beräkningsmodell för ersättning av vinterväghållni ngsåtgärder, version VädErs 2019, fungerar från utgångspunkten, mätdata från VViS och MESAN, till slutfasen ersättningsunderlag i form av väderutfall. Följande händelsekedja visar beräkningsgången i stort . Mätdata från VViS och MESAN → vädersituationer på halvtimmesnivå → vädersituationer på timnivå → vädertillfällen → väderutfall Första delen av händelsekedjan, fram till och med vädersituationer på timnivå, bildar väderbeskriv -\\nningsmodellen. Därefter vidtar kopplingen mellan väder och åtgärdsbehov. 1.2 Mätdata Grunden för en väderbeskrivning är mätdata från enskilda stationer i Trafikverkets system för vägväderinformation, VViS och från MESAN -analyser. VViS -stationerna genererar punktvärden, medan MESAN an ger värden som medeltal över ytor som är 22 x 22 km stora. Följande mätdata från VViS respektive MESAN används i beräkningsmodellen. VViS − Lufttemperatur − Vägytans temperatur − Daggpunktstemperatur MESAN − Nederbördstyp − Nederbördsmängd − Vindhastighet. 1.3 Beräkningsperiod och tidsangivelser Innan beräkningar av vädersituationer och ersättningsunderlag påbörjas läser programmet in väderdata under 14 dagar före beställd starttid. Skälet är att kunna kontrollera om drevbenägen snö finns. Tidsangivelser i beräkningsmodellen anges enligt följande exempel. Timmarna under ett dygn numre -\\nras från 0 till 23. Timme 0 omfattar tidsperioden kl. 0.01–1.00 och delas upp i två halvtimmar, kallade 0.30 för perioden 0.01–0.30 och 1.00 för perioden 0.31 –1.00. Klockslaget ang er en tidpunkt medan timmar och halvtimmar avser tidsperioder. Sambandet mellan tidpunkter och tidsperioder visas nedan. Klockslag 0.00 1.00 2.00 3.00 4.00 5.00 Timme │ 0 │ 1 │ 2 │ 3 │ 4 │ Halvtimme │0.30│1.00│1.30│2.00│2.30│3.00│3.30│4.00│4.30│5.00│'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[2].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text splitter and chuncking configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split PDF text into 63 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "\n",
    "# Split pages into chunks\n",
    "chunks = []\n",
    "for doc in docs:\n",
    "    chunks.extend(text_splitter.split_text(doc.page_content))\n",
    "\n",
    "print(f\"Split PDF text into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 29046.43it/s]\n",
      "Add of existing embedding ID: chunk_0\n",
      "Insert of existing embedding ID: chunk_0\n",
      "Add of existing embedding ID: chunk_1\n",
      "Insert of existing embedding ID: chunk_1\n",
      "Add of existing embedding ID: chunk_2\n",
      "Insert of existing embedding ID: chunk_2\n",
      "Add of existing embedding ID: chunk_3\n",
      "Insert of existing embedding ID: chunk_3\n",
      "Add of existing embedding ID: chunk_4\n",
      "Insert of existing embedding ID: chunk_4\n",
      "Add of existing embedding ID: chunk_5\n",
      "Insert of existing embedding ID: chunk_5\n",
      "Add of existing embedding ID: chunk_6\n",
      "Insert of existing embedding ID: chunk_6\n",
      "Add of existing embedding ID: chunk_7\n",
      "Insert of existing embedding ID: chunk_7\n",
      "Add of existing embedding ID: chunk_8\n",
      "Insert of existing embedding ID: chunk_8\n",
      "Add of existing embedding ID: chunk_9\n",
      "Insert of existing embedding ID: chunk_9\n",
      "Add of existing embedding ID: chunk_10\n",
      "Insert of existing embedding ID: chunk_10\n",
      "Add of existing embedding ID: chunk_11\n",
      "Insert of existing embedding ID: chunk_11\n",
      "Add of existing embedding ID: chunk_12\n",
      "Insert of existing embedding ID: chunk_12\n",
      "Add of existing embedding ID: chunk_13\n",
      "Insert of existing embedding ID: chunk_13\n",
      "Add of existing embedding ID: chunk_14\n",
      "Insert of existing embedding ID: chunk_14\n",
      "Add of existing embedding ID: chunk_15\n",
      "Insert of existing embedding ID: chunk_15\n",
      "Add of existing embedding ID: chunk_16\n",
      "Insert of existing embedding ID: chunk_16\n",
      "Add of existing embedding ID: chunk_17\n",
      "Insert of existing embedding ID: chunk_17\n",
      "Add of existing embedding ID: chunk_18\n",
      "Insert of existing embedding ID: chunk_18\n",
      "Add of existing embedding ID: chunk_19\n",
      "Insert of existing embedding ID: chunk_19\n",
      "Add of existing embedding ID: chunk_20\n",
      "Insert of existing embedding ID: chunk_20\n",
      "Add of existing embedding ID: chunk_21\n",
      "Insert of existing embedding ID: chunk_21\n",
      "Add of existing embedding ID: chunk_22\n",
      "Insert of existing embedding ID: chunk_22\n",
      "Add of existing embedding ID: chunk_23\n",
      "Insert of existing embedding ID: chunk_23\n",
      "Add of existing embedding ID: chunk_24\n",
      "Insert of existing embedding ID: chunk_24\n",
      "Add of existing embedding ID: chunk_25\n",
      "Insert of existing embedding ID: chunk_25\n",
      "Add of existing embedding ID: chunk_26\n",
      "Insert of existing embedding ID: chunk_26\n",
      "Add of existing embedding ID: chunk_27\n",
      "Insert of existing embedding ID: chunk_27\n",
      "Add of existing embedding ID: chunk_28\n",
      "Insert of existing embedding ID: chunk_28\n",
      "Add of existing embedding ID: chunk_29\n",
      "Insert of existing embedding ID: chunk_29\n",
      "Add of existing embedding ID: chunk_30\n",
      "Insert of existing embedding ID: chunk_30\n",
      "Add of existing embedding ID: chunk_31\n",
      "Insert of existing embedding ID: chunk_31\n",
      "Add of existing embedding ID: chunk_32\n",
      "Insert of existing embedding ID: chunk_32\n",
      "Add of existing embedding ID: chunk_33\n",
      "Insert of existing embedding ID: chunk_33\n",
      "Add of existing embedding ID: chunk_34\n",
      "Insert of existing embedding ID: chunk_34\n",
      "Add of existing embedding ID: chunk_35\n",
      "Insert of existing embedding ID: chunk_35\n",
      "Add of existing embedding ID: chunk_36\n",
      "Insert of existing embedding ID: chunk_36\n",
      "Add of existing embedding ID: chunk_37\n",
      "Insert of existing embedding ID: chunk_37\n",
      "Add of existing embedding ID: chunk_38\n",
      "Insert of existing embedding ID: chunk_38\n",
      "Add of existing embedding ID: chunk_39\n",
      "Insert of existing embedding ID: chunk_39\n",
      "Add of existing embedding ID: chunk_40\n",
      "Insert of existing embedding ID: chunk_40\n",
      "Add of existing embedding ID: chunk_41\n",
      "Insert of existing embedding ID: chunk_41\n",
      "Add of existing embedding ID: chunk_42\n",
      "Insert of existing embedding ID: chunk_42\n",
      "Add of existing embedding ID: chunk_43\n",
      "Insert of existing embedding ID: chunk_43\n",
      "Add of existing embedding ID: chunk_44\n",
      "Insert of existing embedding ID: chunk_44\n",
      "Add of existing embedding ID: chunk_45\n",
      "Insert of existing embedding ID: chunk_45\n",
      "Add of existing embedding ID: chunk_46\n",
      "Insert of existing embedding ID: chunk_46\n",
      "Add of existing embedding ID: chunk_47\n",
      "Insert of existing embedding ID: chunk_47\n",
      "Add of existing embedding ID: chunk_48\n",
      "Insert of existing embedding ID: chunk_48\n",
      "Add of existing embedding ID: chunk_49\n",
      "Insert of existing embedding ID: chunk_49\n",
      "Add of existing embedding ID: chunk_50\n",
      "Insert of existing embedding ID: chunk_50\n",
      "Add of existing embedding ID: chunk_51\n",
      "Insert of existing embedding ID: chunk_51\n",
      "Add of existing embedding ID: chunk_52\n",
      "Insert of existing embedding ID: chunk_52\n",
      "Add of existing embedding ID: chunk_53\n",
      "Insert of existing embedding ID: chunk_53\n",
      "Add of existing embedding ID: chunk_54\n",
      "Insert of existing embedding ID: chunk_54\n",
      "Add of existing embedding ID: chunk_55\n",
      "Insert of existing embedding ID: chunk_55\n",
      "Add of existing embedding ID: chunk_56\n",
      "Insert of existing embedding ID: chunk_56\n",
      "Add of existing embedding ID: chunk_57\n",
      "Insert of existing embedding ID: chunk_57\n",
      "Add of existing embedding ID: chunk_58\n",
      "Insert of existing embedding ID: chunk_58\n",
      "Add of existing embedding ID: chunk_59\n",
      "Insert of existing embedding ID: chunk_59\n",
      "Add of existing embedding ID: chunk_60\n",
      "Insert of existing embedding ID: chunk_60\n",
      "Add of existing embedding ID: chunk_61\n",
      "Insert of existing embedding ID: chunk_61\n",
      "Add of existing embedding ID: chunk_62\n",
      "Insert of existing embedding ID: chunk_62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded and indexed chunks in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "# Initialize ChromaDB client (in-memory configuration)\n",
    "client = Client(Settings())\n",
    "\n",
    "# Initialize FastEmbedEmbeddings for embeddings\n",
    "embedder = FastEmbedEmbeddings()\n",
    "\n",
    "# Convert text chunks into embeddings\n",
    "embeddings = embedder.embed_documents(chunks)\n",
    "\n",
    "if \"pdf_docs\" in client.list_collections():\n",
    "    client.delete_collection(\"pdf_docs\")\n",
    "\n",
    "# Create a collection in ChromaDB for storing documents and embeddings\n",
    "collection = client.create_collection(name=\"pdf_docs\", get_or_create=True)\n",
    "\n",
    "# Index each chunk with its embedding in ChromaDB (without metadata)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    collection.add(\n",
    "        documents=[chunk],\n",
    "        embeddings=[embeddings[i]],\n",
    "        metadatas=[{\"chunk_index\": i}],\n",
    "        ids=[f\"chunk_{i}\"]\n",
    "    )\n",
    "\n",
    "print(\"Embedded and indexed chunks in ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.chains import retrieval_qa\n",
    "\n",
    "local_llm = \"llama3.2:1b\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an expert in road weather in the nordics. Your task is to guidance to interpret documents \n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
